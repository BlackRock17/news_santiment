"""
Analysis Workflow - –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –º–µ–∂–¥—É PostgreSQL Reader –∏ AI –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
–ß–µ—Ç–µ –Ω–µ–∞–Ω–∞–ª–∏–∑–∏—Ä–∞–Ω–∏ —Å—Ç–∞—Ç–∏–∏ –æ—Ç –±–∞–∑–∞—Ç–∞ –∏ –≥–∏ –∞–Ω–∞–ª–∏–∑–∏—Ä–∞
"""

import time
import json
from datetime import datetime
from postgres_reader import PostgreSQLReader
from crypto_analyzer import CryptoAnalyzer


class AnalysisWorkflow:
    def __init__(self):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–∞ workflow –∑–∞ –∞–Ω–∞–ª–∏–∑
        """
        print("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–∞–Ω–µ –Ω–∞ Analysis Workflow...")

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–∞–º–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏—Ç–µ
        print("üìä –ó–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ PostgreSQL Reader...")
        self.db_reader = PostgreSQLReader()

        print("ü§ñ –ó–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ AI –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä...")
        self.crypto_analyzer = CryptoAnalyzer()

        print("‚úÖ Analysis Workflow –≥–æ—Ç–æ–≤!")

    def analyze_single_article(self, article_data):
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä–∞ –µ–¥–Ω–∞ —Å—Ç–∞—Ç–∏—è

        Args:
            article_data (dict): –î–∞–Ω–Ω–∏ –∑–∞ —Å—Ç–∞—Ç–∏—è—Ç–∞ –æ—Ç –±–∞–∑–∞—Ç–∞ –¥–∞–Ω–Ω–∏

        Returns:
            dict: –†–µ–∑—É–ª—Ç–∞—Ç –æ—Ç –∞–Ω–∞–ª–∏–∑–∞ –∏–ª–∏ None –∞–∫–æ –∏–º–∞ –≥—Ä–µ—à–∫–∞
        """
        article_id = article_data['id']
        title = article_data['title']
        content = article_data['content']

        print(f"\nüìÑ –ê–Ω–∞–ª–∏–∑–∏—Ä–∞–Ω–µ –Ω–∞ —Å—Ç–∞—Ç–∏—è ID:{article_id}")
        print(f"   –ó–∞–≥–ª–∞–≤–∏–µ: {title[:60]}...")
        print(f"   –î—ä–ª–∂–∏–Ω–∞: {len(content)} —Å–∏–º–≤–æ–ª–∞")

        try:
            # –°—Ç–∞—Ä—Ç–∏—Ä–∞–º–µ AI –∞–Ω–∞–ª–∏–∑
            start_time = time.time()
            analysis_result = self.crypto_analyzer.analyze_crypto_text(content)
            analysis_time = round(time.time() - start_time, 2)

            # –î–æ–±–∞–≤—è–º–µ –º–µ—Ç–∞–¥–∞–Ω–Ω–∏
            analysis_result['metadata'] = {
                'article_id': article_id,
                'article_title': title,
                'article_url': article_data['url'],
                'analyzed_at': datetime.now().isoformat(),
                'analysis_time_seconds': analysis_time
            }

            print(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤—ä—Ä—à–µ–Ω –∑–∞ {analysis_time}s")
            print(
                f"   Sentiment: {analysis_result['sentiment']['label']} ({analysis_result['sentiment']['confidence']:.2f})")

            # –ü–æ–∫–∞–∑–≤–∞–º–µ entities
            total_entities = sum(len(entities) for entities in analysis_result['entities'].values())
            print(f"   Entities: {total_entities} –Ω–∞–º–µ—Ä–µ–Ω–∏")

            return analysis_result

        except Exception as e:
            print(f"‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑ –Ω–∞ —Å—Ç–∞—Ç–∏—è ID:{article_id}: {str(e)}")
            return None

    def process_unanalyzed_articles(self, limit=5, save_results=True):
        """
        –û—Å–Ω–æ–≤–Ω–∏—è—Ç –º–µ—Ç–æ–¥ - –æ–±—Ä–∞–±–æ—Ç–≤–∞ –Ω–µ–∞–Ω–∞–ª–∏–∑–∏—Ä–∞–Ω–∏ —Å—Ç–∞—Ç–∏–∏

        Args:
            limit (int): –ú–∞–∫—Å–∏–º–∞–ª–µ–Ω –±—Ä–æ–π —Å—Ç–∞—Ç–∏–∏ –∑–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞
            save_results (bool): –î–∞–ª–∏ –¥–∞ –∑–∞–ø–∞–∑–≤–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ –≤ JSON —Ñ–∞–π–ª

        Returns:
            dict: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∑–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞—Ç–∞
        """
        print(f"\nüéØ –ó–ê–ü–û–ß–í–ê–ù–ï –ù–ê BATCH –ê–ù–ê–õ–ò–ó")
        print(f"üîç –¢—ä—Ä—Å–µ–Ω–µ –Ω–∞ –¥–æ {limit} –Ω–µ–∞–Ω–∞–ª–∏–∑–∏—Ä–∞–Ω–∏ —Å—Ç–∞—Ç–∏–∏...")

        # –°—Ç—ä–ø–∫–∞ 1: –í–∑–µ–º–∞–º–µ –Ω–µ–∞–Ω–∞–ª–∏–∑–∏—Ä–∞–Ω–∏ —Å—Ç–∞—Ç–∏–∏
        articles = self.db_reader.get_unanalyzed_articles(limit=limit)

        if not articles:
            print("üìã –ù—è–º–∞ –Ω–µ–∞–Ω–∞–ª–∏–∑–∏—Ä–∞–Ω–∏ —Å—Ç–∞—Ç–∏–∏ –∑–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞")
            return {
                'total_articles': 0,
                'successful_analyses': 0,
                'failed_analyses': 0,
                'processing_time': 0
            }

        print(f"üì∞ –ù–∞–º–µ—Ä–µ–Ω–∏ {len(articles)} —Å—Ç–∞—Ç–∏–∏ –∑–∞ –∞–Ω–∞–ª–∏–∑")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        successful_count = 0
        failed_count = 0
        analysis_results = []

        start_time = time.time()

        # –°—Ç—ä–ø–∫–∞ 2: –ê–Ω–∞–ª–∏–∑–∏—Ä–∞–º–µ –≤—Å—è–∫–∞ —Å—Ç–∞—Ç–∏—è
        for i, article in enumerate(articles, 1):
            print(f"\n[{i}/{len(articles)}] " + "=" * 50)

            # –ê–Ω–∞–ª–∏–∑–∏—Ä–∞–º–µ —Å—Ç–∞—Ç–∏—è—Ç–∞
            analysis_result = self.analyze_single_article(article)

            if analysis_result:
                # –°—Ç—ä–ø–∫–∞ 3: –ú–∞—Ä–∫–∏—Ä–∞–º–µ –∫–∞—Ç–æ –∞–Ω–∞–ª–∏–∑–∏—Ä–∞–Ω–∞
                success = self.db_reader.mark_article_as_analyzed(
                    article['id'],
                    analysis_summary=analysis_result['summary']
                )

                if success:
                    successful_count += 1
                    analysis_results.append(analysis_result)
                    print(f"‚úÖ –°—Ç–∞—Ç–∏—è {i} —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–µ–Ω–∞ –∏ –º–∞—Ä–∫–∏—Ä–∞–Ω–∞")
                else:
                    failed_count += 1
                    print(f"‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –º–∞—Ä–∫–∏—Ä–∞–Ω–µ –Ω–∞ —Å—Ç–∞—Ç–∏—è {i}")
            else:
                failed_count += 1
                print(f"‚ùå –ê–Ω–∞–ª–∏–∑—ä—Ç –Ω–∞ —Å—Ç–∞—Ç–∏—è {i} —Å–µ –ø—Ä–æ–≤–∞–ª–∏")

            # –ú–∞–ª–∫–∞ –ø–∞—É–∑–∞ –º–µ–∂–¥—É —Å—Ç–∞—Ç–∏–∏—Ç–µ
            if i < len(articles):
                print("‚è≥ –ü–∞—É–∑–∞ 2 —Å–µ–∫—É–Ω–¥–∏...")
                time.sleep(2)

        # –°—Ç—ä–ø–∫–∞ 4: –û–±–æ–±—â–µ–Ω–∏–µ
        total_time = round(time.time() - start_time, 2)

        print(f"\n" + "=" * 60)
        print(f"üéâ BATCH –ê–ù–ê–õ–ò–ó –ó–ê–í–™–†–®–ï–ù!")
        print(f"üìä –†–ï–ó–£–õ–¢–ê–¢–ò:")
        print(f"   üì∞ –û–±—â–æ —Å—Ç–∞—Ç–∏–∏: {len(articles)}")
        print(f"   ‚úÖ –£—Å–ø–µ—à–Ω–∏: {successful_count}")
        print(f"   ‚ùå –ù–µ—É—Å–ø–µ—à–Ω–∏: {failed_count}")
        print(f"   üïí –û–±—â–æ –≤—Ä–µ–º–µ: {total_time}s")
        print(f"   ‚ö° –°—Ä–µ–¥–Ω–æ –≤—Ä–µ–º–µ/—Å—Ç–∞—Ç–∏—è: {total_time / len(articles):.1f}s")

        # –°—Ç—ä–ø–∫–∞ 5: –ó–∞–ø–∞–∑–≤–∞–º–µ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª–Ω–æ)
        if save_results and analysis_results:
            self.save_analysis_results(analysis_results)

        # –ü–æ–∫–∞–∑–≤–∞–º–µ –æ–±–Ω–æ–≤–µ–Ω–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –æ—Ç –±–∞–∑–∞—Ç–∞ –¥–∞–Ω–Ω–∏
        updated_stats = self.db_reader.get_database_stats()
        print(f"\nüìä –û–ë–ù–û–í–ï–ù–ò –°–¢–ê–¢–ò–°–¢–ò–ö–ò –û–¢ –ë–ê–ó–ê–¢–ê:")
        print(f"   üì∞ –û–±—â–æ —Å—Ç–∞—Ç–∏–∏: {updated_stats['total_articles']}")
        print(f"   ‚úÖ –ê–Ω–∞–ª–∏–∑–∏—Ä–∞–Ω–∏: {updated_stats['analyzed_articles']}")
        print(f"   ‚è≥ –ù–µ–∞–Ω–∞–ª–∏–∑–∏—Ä–∞–Ω–∏: {updated_stats['unanalyzed_articles']}")

        return {
            'total_articles': len(articles),
            'successful_analyses': successful_count,
            'failed_analyses': failed_count,
            'processing_time': total_time,
            'analysis_results': analysis_results
        }

    def save_analysis_results(self, analysis_results):
        """
        –ó–∞–ø–∞–∑–≤–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ –æ—Ç –∞–Ω–∞–ª–∏–∑–∞ –≤ JSON —Ñ–∞–π–ª

        Args:
            analysis_results (list): –°–ø–∏—Å—ä–∫ —Å —Ä–µ–∑—É–ª—Ç–∞—Ç–∏ –æ—Ç –∞–Ω–∞–ª–∏–∑–∞
        """
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"analysis_results_{timestamp}.json"

        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(analysis_results, f, ensure_ascii=False, indent=2, default=str)

            print(f"üíæ –†–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ –∑–∞–ø–∞–∑–µ–Ω–∏ –≤ —Ñ–∞–π–ª: {filename}")
            print(f"   üìä {len(analysis_results)} –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–ø–∞–∑–µ–Ω–∏")

        except Exception as e:
            print(f"‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –∑–∞–ø–∞–∑–≤–∞–Ω–µ –Ω–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ: {e}")

    def get_workflow_status(self):
        """
        –ü–æ–∫–∞–∑–≤–∞ —Å—Ç–∞—Ç—É—Å –Ω–∞ workflow-–∞ - –∫–∞–∫–≤–æ –∏–º–∞ –∑–∞ –∞–Ω–∞–ª–∏–∑–∏—Ä–∞–Ω–µ
        """
        print("\nüìä WORKFLOW STATUS")
        print("=" * 30)

        try:
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –æ—Ç –±–∞–∑–∞—Ç–∞ –¥–∞–Ω–Ω–∏
            stats = self.db_reader.get_database_stats()

            print("üìà –ë–∞–∑–∞ –¥–∞–Ω–Ω–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏:")
            print(f"   üì∞ –û–±—â–æ —Å—Ç–∞—Ç–∏–∏: {stats['total_articles']}")
            print(f"   ‚úÖ –ê–Ω–∞–ª–∏–∑–∏—Ä–∞–Ω–∏: {stats['analyzed_articles']}")
            print(f"   ‚è≥ –ù–µ–∞–Ω–∞–ª–∏–∑–∏—Ä–∞–Ω–∏: {stats['unanalyzed_articles']}")

            if stats['latest_article']:
                title, date = stats['latest_article']
                print(f"   üìÖ –ù–∞–π-–Ω–æ–≤–∞: {title[:40]}... ({date})")

            # –ü–æ–∫–∞–∑–≤–∞–º–µ –ø—ä—Ä–≤–∏—Ç–µ –Ω–µ–∞–Ω–∞–ª–∏–∑–∏—Ä–∞–Ω–∏ —Å—Ç–∞—Ç–∏–∏
            if stats['unanalyzed_articles'] > 0:
                print(f"\nüìã –°–ª–µ–¥–≤–∞—â–∏ —Å—Ç–∞—Ç–∏–∏ –∑–∞ –∞–Ω–∞–ª–∏–∑:")
                unanalyzed = self.db_reader.get_unanalyzed_articles(limit=5)

                for i, article in enumerate(unanalyzed, 1):
                    print(f"   {i}. ID:{article['id']} | {article['title'][:50]}...")
                    print(f"      üìä {article['content_length']} chars | {article['scraped_at']}")

                print(
                    f"\nüí° –ü—Ä–µ–ø–æ—Ä—ä–∫–∞: python analysis_workflow.py analyze --limit {min(stats['unanalyzed_articles'], 5)}")
            else:
                print(f"\n‚úÖ –í—Å–∏—á–∫–∏ —Å—Ç–∞—Ç–∏–∏ —Å–∞ –∞–Ω–∞–ª–∏–∑–∏—Ä–∞–Ω–∏!")
                print(f"üí° –î–æ–±–∞–≤–∏ –Ω–æ–≤–∏ —Å—Ç–∞—Ç–∏–∏ —Å—ä—Å scraper-–∞ –∑–∞ –¥–∞ –ø—Ä–æ–¥—ä–ª–∂–∏—à –∞–Ω–∞–ª–∏–∑–∞")

        except Exception as e:
            print(f"‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –ø–æ–∫–∞–∑–≤–∞–Ω–µ –Ω–∞ —Å—Ç–∞—Ç—É—Å: {e}")


# –¢–µ—Å—Ç–æ–≤–∏ —Ñ—É–Ω–∫—Ü–∏–∏
def test_workflow():
    """
    –¢–µ—Å—Ç–≤–∞ workflow-–∞ —Å –µ–¥–Ω–∞ —Å—Ç–∞—Ç–∏—è
    """
    print("=== –¢–ï–°–¢ –ù–ê ANALYSIS WORKFLOW ===")

    try:
        # –°—ä–∑–¥–∞–≤–∞–º–µ workflow
        workflow = AnalysisWorkflow()

        # –ü–æ–∫–∞–∑–≤–∞–º–µ —Å—Ç–∞—Ç—É—Å
        workflow.get_workflow_status()

        # –¢–µ—Å—Ç–≤–∞–º–µ —Å 1 —Å—Ç–∞—Ç–∏—è
        print(f"\nüß™ –¢–ï–°–¢: –ê–Ω–∞–ª–∏–∑ –Ω–∞ 1 —Å—Ç–∞—Ç–∏—è")
        results = workflow.process_unanalyzed_articles(limit=1, save_results=True)

        if results['successful_analyses'] > 0:
            print(f"\nüéâ Workflow —Ç–µ—Å—Ç –£–°–ü–ï–®–ï–ù!")
            print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∞–Ω–∞–ª–∏–∑–∏—Ä–∞–Ω–∞ {results['successful_analyses']} —Å—Ç–∞—Ç–∏—è")
            return True
        else:
            print(f"\n‚ö†Ô∏è Workflow —Ç–µ—Å—Ç - –Ω—è–º–∞ —Å—Ç–∞—Ç–∏–∏ –∑–∞ –∞–Ω–∞–ª–∏–∑")
            return True  # –ù–µ –µ –≥—Ä–µ—à–∫–∞ –∞–∫–æ –Ω—è–º–∞ —Å—Ç–∞—Ç–∏–∏

    except Exception as e:
        print(f"\n‚ùå Workflow —Ç–µ—Å—Ç –Ω–µ—É—Å–ø–µ—à–µ–Ω: {e}")
        return False


def main():
    """
    –û—Å–Ω–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü–∏—è –∑–∞ —Ç–µ—Å—Ç–≤–∞–Ω–µ
    """
    print("=== ANALYSIS WORKFLOW –°–ò–°–¢–ï–ú–ê ===")

    try:
        # –¢–µ—Å—Ç–≤–∞–º–µ workflow-–∞
        success = test_workflow()

        if success:
            print(f"\nüöÄ Analysis Workflow –µ –≥–æ—Ç–æ–≤ –∑–∞ –∏–∑–ø–æ–ª–∑–≤–∞–Ω–µ!")
            print(f"\nüìù –ö–æ–º–∞–Ω–¥–Ω–∏ –æ–ø—Ü–∏–∏:")
            print(f"   python analysis_workflow.py                    # –¢–µ—Å—Ç")
            print(f"   workflow.process_unanalyzed_articles(limit=5)  # –ê–Ω–∞–ª–∏–∑ –Ω–∞ 5 —Å—Ç–∞—Ç–∏–∏")
            print(f"   workflow.get_workflow_status()                 # –°—Ç–∞—Ç—É—Å")
        else:
            print(f"\n‚ùå –ò–º–∞ –ø—Ä–æ–±–ª–µ–º–∏ —Å workflow-–∞")

    except Exception as e:
        print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–Ω–∞ –≥—Ä–µ—à–∫–∞: {e}")


if __name__ == "__main__":
    main()
